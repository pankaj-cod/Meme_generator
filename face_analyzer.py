"""
Face detection and emotion analysis module
"""
import cv2
import numpy as np
import random
import os

class FaceAnalyzer:
    def __init__(self):
        """Initialize face detection model"""
        # Use OpenCV's Haar Cascade for face detection
        cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        self.face_cascade = cv2.CascadeClassifier(cascade_path)
        
        # Emotion list for demo purposes
        self.emotions = ['happy', 'sad', 'angry', 'surprise', 'fear', 'disgust', 'neutral']
        
    def detect_faces(self, image_path):
        """
        Detect faces in an image using OpenCV Haar Cascade
        
        Args:
            image_path: Path to the image file
            
        Returns:
            tuple: (number of faces detected, image with face boxes)
        """
        # Read image
        image = cv2.imread(image_path)
        if image is None:
            return 0, None
            
        # Convert to grayscale for face detection
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Detect faces
        faces = self.face_cascade.detectMultiScale(
            gray,
            scaleFactor=1.1,
            minNeighbors=5,
            minSize=(30, 30)
        )
        
        face_count = len(faces)
        
        # Draw bounding boxes
        for (x, y, w, h) in faces:
            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)
        
        return face_count, image
    
    def analyze_emotion(self, image_path):
        """
        Analyze facial emotion using basic image analysis
        
        Note: This is a simplified version for demonstration.
        For production, consider using a pre-trained deep learning model.
        
        Args:
            image_path: Path to the image file
            
        Returns:
            dict: Analysis results including dominant emotion and all emotion scores
        """
        try:
            # Read image
            image = cv2.imread(image_path)
            if image is None:
                return {
                    'success': False,
                    'error': 'Could not read image',
                    'dominant_emotion': 'neutral',
                    'emotion_scores': {},
                    'confidence': 0
                }
            
            # Convert to grayscale for analysis
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # Basic brightness analysis (simplified emotion detection)
            # In a real implementation, you would use a trained ML model
            avg_brightness = np.mean(gray)
            
            # Generate pseudo-realistic emotion scores based on image properties
            # This is for demonstration - replace with actual ML model in production
            emotion_scores = {}
            
            # Use image properties to influence emotion distribution
            seed = int(avg_brightness * gray.shape[0] * gray.shape[1]) % 1000
            random.seed(seed)
            
            # Generate weighted random scores
            weights = [30, 15, 10, 15, 10, 10, 10]  # Bias towards happy/neutral
            for i, emotion in enumerate(self.emotions):
                base_score = random.uniform(5, weights[i])
                emotion_scores[emotion] = round(base_score, 2)
            
            # Normalize to 100%
            total = sum(emotion_scores.values())
            emotion_scores = {k: round((v / total) * 100, 2) for k, v in emotion_scores.items()}
            
            # Find dominant emotion
            dominant_emotion = max(emotion_scores, key=emotion_scores.get)
            confidence = emotion_scores[dominant_emotion]
            
            return {
                'success': True,
                'dominant_emotion': dominant_emotion,
                'emotion_scores': emotion_scores,
                'confidence': round(confidence, 2)
            }
            
        except Exception as e:
            print(f"Error analyzing emotion: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'dominant_emotion': 'neutral',
                'emotion_scores': {},
                'confidence': 0
            }
    
    def get_emotion_description(self, emotion):
        """
        Get a human-readable description of the emotion
        
        Args:
            emotion: The detected emotion
            
        Returns:
            str: Description of the emotion
        """
        descriptions = {
            'happy': 'You look happy! üòä',
            'sad': 'You seem a bit sad üò¢',
            'angry': 'Someone looks angry! üò†',
            'surprise': 'What a surprise! üò≤',
            'fear': 'Looking a bit scared üò®',
            'disgust': 'Not impressed, huh? ü§¢',
            'neutral': 'Keeping it cool and neutral üòê'
        }
        return descriptions.get(emotion, 'Interesting expression!')
    
    def cleanup(self):
        """Release resources"""
        pass  # No resources to release for Haar Cascade
